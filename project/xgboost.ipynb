{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import get_datasets\n",
    "datasets = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.small.resplit(0.75,0,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "train = data.train_split\n",
    "train0 = train.X[train.y==0].copy()\n",
    "train1 = train.X[train.y==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xy(X=                var_0   var_1    var_2   var_3    var_4    var_5   var_6  \\\n",
       "ID_code                                                                    \n",
       "train_49227   15.0292  0.0845   7.0515  9.6233  11.0724 -11.8830  5.4014   \n",
       "train_101761  13.0058  5.8709   8.6504  5.9633  11.6448   5.8945  5.5764   \n",
       "train_37110   16.4113  7.7975   9.7316  4.0067  10.8215  -7.0870  4.4055   \n",
       "train_152074   7.6395 -4.5843   8.9218  3.6761  13.6540  -7.1728  5.6390   \n",
       "train_111902  17.9596 -4.1012   8.5002  3.5160  11.4328  -7.9076  5.9981   \n",
       "...               ...     ...      ...     ...      ...      ...     ...   \n",
       "train_115548  10.8425 -7.6605  10.5641  8.4076  10.9474 -19.2507  4.6391   \n",
       "train_42786    9.5460 -7.7474  18.6354  7.3233  13.0006  -3.2523  5.4781   \n",
       "train_129969   8.3900  3.8427  14.3383  9.7263  10.5655 -12.1030  6.0262   \n",
       "train_162783  17.4012  2.5168   9.6433  8.0242  12.7171  -2.6001  4.5290   \n",
       "train_67210   13.3044 -2.7513  12.1481  8.8079  12.6856 -12.2704  5.4606   \n",
       "\n",
       "                var_7   var_8   var_9  ...  var_190  var_191  var_192  \\\n",
       "ID_code                                ...                              \n",
       "train_49227   13.1310 -0.5920  7.1253  ...   4.3579  12.2855   2.6584   \n",
       "train_101761  13.2528  1.2523  7.7552  ...  -1.5616   5.3425   1.5546   \n",
       "train_37110   12.9940 -3.0346  8.4304  ...   3.4215   8.3624   1.1755   \n",
       "train_152074  15.4577  4.3630  6.4463  ...   1.6336  11.0626   3.0927   \n",
       "train_111902  14.2791 -2.9938  8.4610  ...   8.7129  10.2722   3.3035   \n",
       "...               ...     ...     ...  ...      ...      ...      ...   \n",
       "train_115548  18.2678 -6.1625  7.1116  ...   0.2470   7.4110   4.1139   \n",
       "train_42786   20.2583  5.2616  8.7824  ...   7.9117   5.2246  -0.2957   \n",
       "train_129969  20.4288  1.1407  8.1612  ...  -0.8732   8.7984   2.0128   \n",
       "train_162783  18.4739  2.8552  7.1677  ...  -0.3503   2.8918   2.0578   \n",
       "train_67210   19.8116  1.2726  5.6800  ...   4.4677   3.2200   4.0421   \n",
       "\n",
       "              var_193  var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "ID_code                                                                      \n",
       "train_49227    2.3329  22.4276  -1.2867   6.1107   8.0833  12.7790  -5.7793  \n",
       "train_101761   1.5068  21.5083  -0.1826   1.7163   7.3626  15.8551   8.2346  \n",
       "train_37110   -0.6118  19.3641  -0.1262  -4.5252   9.4489  13.6566 -30.5616  \n",
       "train_152074   3.1701  18.0378   0.9150  -0.7154   8.0243  20.1346  -2.8529  \n",
       "train_111902   8.3779  20.2022  -0.5690   9.5222  10.8146  16.9564  -2.7137  \n",
       "...               ...      ...      ...      ...      ...      ...      ...  \n",
       "train_115548   9.8769  13.3768   0.9738   6.9549   8.1277  22.4873   5.2036  \n",
       "train_42786    4.1940  15.8485  -0.6026  -2.3535  10.4347  15.2085   2.8234  \n",
       "train_129969   5.0870  13.5424   1.8414  -5.8822   8.1447  15.1325  -5.2060  \n",
       "train_162783   4.2860  13.9330  -0.2305  -0.8895   8.5641  13.0926  -0.3488  \n",
       "train_67210    0.0707  21.1249   0.2018   5.0288   9.7462  16.8677 -14.5811  \n",
       "\n",
       "[52542 rows x 200 columns], y=ID_code\n",
       "train_49227     0\n",
       "train_101761    1\n",
       "train_37110     0\n",
       "train_152074    0\n",
       "train_111902    0\n",
       "               ..\n",
       "train_115548    0\n",
       "train_42786     0\n",
       "train_129969    0\n",
       "train_162783    0\n",
       "train_67210     0\n",
       "Name: target, Length: 52542, dtype: int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE MEANS AND STANDARD DEVIATIONS\n",
    "s = [0]*200\n",
    "m = [0]*200\n",
    "rmin=-5; rmax=5; \n",
    "res=501\n",
    "for i in range(200):\n",
    "    s[i] = np.std(train.X['var_'+str(i)])\n",
    "    m[i] = np.mean(train.X['var_'+str(i)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE PROB(TARGET=1 | X)\n",
    "def getp(i,x):\n",
    "    c = 3 #smoothing factor\n",
    "    a = len( train1[ (train1['var_'+str(i)]>x-s[i]/c)&(train1['var_'+str(i)]<x+s[i]/c) ] ) \n",
    "    b = len( train0[ (train0['var_'+str(i)]>x-s[i]/c)&(train0['var_'+str(i)]<x+s[i]/c) ] )\n",
    "    if a+b<500: return 0.1 #smoothing factor\n",
    "    # RETURN PROBABILITY\n",
    "    return a / (a+b)\n",
    "    # ALTERNATIVELY RETURN ODDS\n",
    "    # return a / b\n",
    "    \n",
    "# SMOOTH A DISCRETE FUNCTION\n",
    "def smooth(x,st=1):\n",
    "    for j in range(st):\n",
    "        x2 = np.ones(len(x)) * 0.1\n",
    "        for i in range(len(x)-2):\n",
    "            x2[i+1] = 0.25*x[i]+0.5*x[i+1]+0.25*x[i+2]\n",
    "        x = x2.copy()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing vars 0 to 7 ...\n",
      "Showing vars 8 to 15 ...\n",
      "Showing vars 16 to 23 ...\n",
      "Showing vars 24 to 31 ...\n",
      "Showing vars 32 to 39 ...\n",
      "Showing vars 40 to 47 ...\n",
      "Showing vars 48 to 55 ...\n",
      "Showing vars 56 to 63 ...\n",
      "Showing vars 64 to 71 ...\n",
      "Showing vars 72 to 79 ...\n",
      "Showing vars 80 to 87 ...\n",
      "Showing vars 88 to 95 ...\n",
      "Showing vars 96 to 103 ...\n",
      "Showing vars 104 to 111 ...\n",
      "Showing vars 112 to 119 ...\n",
      "Showing vars 120 to 127 ...\n",
      "Showing vars 128 to 135 ...\n",
      "Showing vars 136 to 143 ...\n",
      "Showing vars 144 to 151 ...\n",
      "Showing vars 152 to 159 ...\n",
      "Showing vars 160 to 167 ...\n",
      "Showing vars 168 to 175 ...\n",
      "Showing vars 176 to 183 ...\n",
      "Showing vars 184 to 191 ...\n",
      "Showing vars 192 to 199 ...\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# DRAW PLOTS, YES OR NO\n",
    "Picture = False\n",
    "# DATA HAS Z-SCORE RANGE OF -4.5 TO 4.5\n",
    "rmin=-5; rmax=5; \n",
    "# CALCULATE PROBABILITIES FOR 501 BINS\n",
    "res=501\n",
    "# STORE PROBABILITIES IN PR\n",
    "pr = 0.1 * np.ones((200,res))\n",
    "pr2 = pr.copy()\n",
    "xr = np.zeros((200,res))\n",
    "xr2 = xr.copy()\n",
    "ct2 = 0\n",
    "for j in range(50):\n",
    "    if Picture: plt.figure(figsize=(15,8))\n",
    "    for v in range(4):\n",
    "        ct = 0\n",
    "        # CALCULATE PROBABILITY FUNCTION FOR VAR\n",
    "        for i in np.linspace(rmin,rmax,res):\n",
    "            pr[v+4*j,ct] = getp(v+4*j,m[v+4*j]+i*s[v+4*j])\n",
    "            xr[v+4*j,ct] = m[v+4*j]+i*s[v+4*j]\n",
    "            xr2[v+4*j,ct] = i\n",
    "            ct += 1\n",
    "        if Picture:\n",
    "            # SMOOTH FUNCTION FOR PRETTIER DISPLAY\n",
    "            # BUT USE UNSMOOTHED FUNCTION FOR PREDICTION\n",
    "            pr2[v+4*j,:] = smooth(pr[v+4*j,:],res//10)\n",
    "            # DISPLAY PROBABILITY FUNCTION\n",
    "            plt.subplot(2, 4, ct2%4+5)\n",
    "            plt.plot(xr[v+4*j,:],pr2[v+4*j,:],'-')\n",
    "            plt.title('P( t=1 | var_'+str(v+4*j)+' )')\n",
    "            xx = plt.xlim()\n",
    "            # DISPLAY TARGET DENSITIES\n",
    "            plt.subplot(2, 4, ct2%4+1)            \n",
    "            sns.distplot(train0['var_'+str(v+4*j)], label = 't=0')\n",
    "            sns.distplot(train1['var_'+str(v+4*j)], label = 't=1')\n",
    "            plt.title('var_'+str(v+4*j))\n",
    "            plt.legend()\n",
    "            plt.xlim(xx)\n",
    "            plt.xlabel('')\n",
    "        if (ct2%8==0): print('Showing vars',ct2,'to',ct2+7,'...')\n",
    "        ct2 += 1\n",
    "    if Picture: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getp2(i,x):\n",
    "    z = (x-m[i])/s[i]\n",
    "    ss = (rmax-rmin)/(res-1)\n",
    "    if res%2==0: idx = min( (res+1)//2 + z//ss, res-1)\n",
    "    else: idx = min( (res+1)//2 + (z-ss/2)//ss, res-1)\n",
    "    idx = max(idx,0)\n",
    "    return pr[i,int(idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 200000 predictions and displaying a few examples...\n",
      "train 0 has target = 0 and prediction = 0.018506942499466907\n",
      "train 25000 has target = 0 and prediction = 0.06543276319609491\n",
      "train 50000 has target = 0 and prediction = 0.0016910019150256882\n",
      "###############\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-dc1d90523c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'###############'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation AUC ='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Calculating 200000 predictions and displaying a few examples...')\n",
    "pred = [0]*200000; ct = 0\n",
    "for r in range(train.X.index.shape[0]):\n",
    "    p = 0.1\n",
    "    for i in range(200):\n",
    "        p *= 10*getp2(i,train.X.iloc[r,i])\n",
    "    if ct%25000==0: print('train',r,'has target =',train.y.iloc[r],'and prediction =',p)\n",
    "    pred[ct]=p; ct += 1\n",
    "print('###############')\n",
    "print('Validation AUC =',roc_auc_score(train.y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [52542, 200000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-2dfef076d491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'###############'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation AUC ='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/host2019/VisInt/venv/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    353\u001b[0m     return _average_binary_score(\n\u001b[1;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/host2019/VisInt/venv/lib/python3.7/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/host2019/VisInt/venv/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 327\u001b[0;31m                                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/host2019/VisInt/venv/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/host2019/VisInt/venv/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/host2019/VisInt/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [52542, 200000]"
     ]
    }
   ],
   "source": [
    "print('###############')\n",
    "print('Validation AUC =',roc_auc_score(train.y[:200000], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0845"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.X.iloc[0,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
